{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment graphical interface\n",
    "\n",
    "\n",
    "In order to assess relevance of documents, you will have to create a web interface that displays the topic/query, and a given document list. Each URL in the list should be clickable to lead to the document text, pooled either from ES raw-html field or live from original URL. You would probably take as a start the web GUI you used for vertical search in HW3.\n",
    "\n",
    "The interface has to contain an input fields for each URL/snippet in order for the assessor to input a 3-scale grade “non-relevant”, “relevant”, “very relevant” (or 0,1,2). The can be an input checkboxes, radio boxes, dropdown list, text input box, etc. The interface should also record the assessor ID (by name). You can add a “submit” button somewhere, and a count of how many documents have been assessed.\n",
    "\n",
    "The input assessments should be stored in a QREL file (txt format) as\n",
    "\n",
    "QueryID AssessorID DocID Grade\n",
    "\n",
    "QueryID AssessorID DocID Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import statistics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class OpenRead:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def file_open_read(self, filename):\n",
    "        with open(filename,encoding=\"utf-8\") as file:\n",
    "            file = file.readlines()\n",
    "        file_content = [i.split(\"\\t\") for i in file]\n",
    "        modified_file_content = []\n",
    "        if \"karan\" in filename.lower():\n",
    "            for content in file_content:\n",
    "                if \"Karan\" in content:\n",
    "                    if len(content[0]) != 6:\n",
    "                        content[0] = content[0].split()[-1]\n",
    "                    if len(content) != 4:\n",
    "                        split_content = content[-1].split()\n",
    "                        content[-1] = split_content[0]\n",
    "                        content.append(split_content[-1].strip(\"\\\\\"))\n",
    "                    else:\n",
    "                        content[-1] = content[-1].strip(\"\\\\\\n\")\n",
    "                    modified_file_content.append(content)\n",
    "            file_content = modified_file_content\n",
    "        else:   \n",
    "            for i in file_content:\n",
    "                if i != [\"\\n\"]:\n",
    "                    try:\n",
    "                        i[3] = i[3].strip(\"\\n\")\n",
    "                    except:\n",
    "                        print (i)\n",
    "                        return \n",
    "                else:\n",
    "                    file_content.remove(i)\n",
    "        return file_content\n",
    "    \n",
    "    def list_to_dict(self, list_to_change):\n",
    "        dict_query = {}\n",
    "        for element in list_to_change:\n",
    "            dict_query[element[2]] = element[:2] + [element[-1]]\n",
    "        return dict_query \n",
    "    \n",
    "    def combine_result(self, result_query):\n",
    "        dict_monica_query = result_query[0]\n",
    "        dict_bagus_query = result_query[1]\n",
    "        dict_karan_query = result_query[2]\n",
    "        new_dict = {}\n",
    "        for url in dict_monica_query:\n",
    "            if url in dict_bagus_query and url in dict_karan_query:\n",
    "                result_1 = [dict_bagus_query[url][2]]\n",
    "                result_2 = [dict_karan_query[url][2]]\n",
    "                new_dict[url] = [dict_monica_query[url][2]] + result_1 + result_2\n",
    "            else:\n",
    "                if url not in dict_karan_query and url in dict_bagus_query:\n",
    "                    ## add the same entry\n",
    "                    new_dict[url] = [dict_monica_query[url][2]] + result_1 + result_1\n",
    "        return new_dict\n",
    "    \n",
    "    def filename_open_to_list(self):\n",
    "        filenames = [[\"152601_monica.txt\", \"152601_bagus.txt\", \"152601_karan.rtf\"],[\"152602_monica.txt\", \"152602_bagus.txt\", \"152602_karan.rtf\"],\n",
    "                     [\"152603_monica.txt\", \"152603_bagus.txt\", \"152603_karan.rtf\"]]\n",
    "        self.complete_result_set = {}\n",
    "        for name in filenames:\n",
    "            result_query = []\n",
    "            for query_each in name:\n",
    "                list_per_query = self.file_open_read(query_each)\n",
    "                dict_per_query = self.list_to_dict(list_per_query)\n",
    "                result_query.append(dict_per_query)\n",
    "                print (\"Completed parsing\", query_each)\n",
    "            new_dict_combined = self.combine_result(result_query)    \n",
    "            self.complete_result_set[query_each.split(\"_\")[0]] = new_dict_combined\n",
    "        file_name_overall, file_name_binary = self.overall_relevance_judgement()\n",
    "        return file_name_overall, file_name_binary\n",
    "    \n",
    "    ## get overall judgement on a query\n",
    "    def overall_relevance_judgement(self):\n",
    "        file_name_overall = (\"crawler_query\") + \"_overall.txt\"\n",
    "        file_name_binary = (\"crawler_query\") + \"_binary.txt\"\n",
    "        for query in self.complete_result_set:\n",
    "            overall_relevance_dict = {}\n",
    "            binary_relevance_dict = {}\n",
    "            for key,value in self.complete_result_set[query].items():\n",
    "                try:\n",
    "                    value = int(statistics.mode(value))\n",
    "                except Exception as e:\n",
    "                    value = 1 #median value since no mode was found\n",
    "                if value == 1:\n",
    "                    bin_value = 0\n",
    "                elif value == 2:\n",
    "                    bin_value = 1\n",
    "                binary_relevance_dict[key] = bin_value \n",
    "                overall_relevance_dict[key] = value\n",
    "            self.write_into_file(query, file_name_binary, binary_relevance_dict)\n",
    "            self.write_into_file(query, file_name_overall, overall_relevance_dict)\n",
    "        return file_name_overall, file_name_binary\n",
    "    \n",
    "    def write_into_file(self, query, file_name, dictionary):\n",
    "         with open(file_name, \"a+\") as file:\n",
    "            for key in dictionary:\n",
    "                str_file = str(query) + \" \" + str(key) + \" \" + str(dictionary[key]) + \"\\n\"\n",
    "                file.write(str_file)\n",
    "                    \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed parsing 152601_monica.txt\n",
      "Completed parsing 152601_bagus.txt\n",
      "Completed parsing 152601_karan.rtf\n",
      "Completed parsing 152602_monica.txt\n",
      "Completed parsing 152602_bagus.txt\n",
      "Completed parsing 152602_karan.rtf\n",
      "Completed parsing 152603_monica.txt\n",
      "Completed parsing 152603_bagus.txt\n",
      "Completed parsing 152603_karan.rtf\n"
     ]
    }
   ],
   "source": [
    "open_read_object = OpenRead()\n",
    "file_name_overall, file_name_binary = open_read_object.filename_open_to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write your own trec_eval\n",
    "\n",
    "Write a program that replicates trec_eval functionality. Input : a ranked list file and QREL file, both in TREC format. Both files can contain results and assessments for multiple queryIDs.\n",
    "\n",
    "First, sort docIDS per queryID by score. Then for each query compute R-precision, Average Precision, nDCG, precision@k and recall@k and F1@k (k=5,10, 20, 50, 100). Average these numbers over the queryIDs. If run with -q option your program should display the measures for each queryID before displaying the averages.\n",
    "\n",
    "Run your treceval on HW1 runs with the qrel provided to confirm that it gives the same values as the provided treceval.\n",
    "\n",
    "Run your trec_eval on the HW3 vertical search engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JudgementClassification():\n",
    "    def __init__(self, file_name_overall = None, file_name_binary = None, query_num = None, trec_file = None):\n",
    "        self.indices = [5-1, 10-1, 20-1, 50-1, 100-1, 200-1]\n",
    "        self.result_dict = {}\n",
    "        self.query_num = query_num\n",
    "        self.binary_filename = file_name_binary\n",
    "        self.overall_filename = file_name_overall\n",
    "        self.trec_file = trec_file\n",
    "        self.query_num = query_num\n",
    "        self.ndgc_all = {}\n",
    "        \n",
    "    def call_func(self):\n",
    "        self.result_dict = {}\n",
    "        if self.overall_filename:\n",
    "            self.overall_relevance_dict = self.qrel_parser(self.overall_filename)\n",
    "            self.overall_trec_dictionary = self.trec_relevance_reader(self.trec_file)  \n",
    "            self.overall_trec_dictionary  = self.trec_relevance_conversion(self.overall_trec_dictionary, self.overall_relevance_dict) \n",
    "            self.ndgc_all = {}\n",
    "            for key in self.overall_trec_dictionary:\n",
    "                self.ndgc_all[key] = self.calculate_ndcg(self.overall_trec_dictionary[key])   \n",
    "        else:\n",
    "            print (\"Since overall relevance file is not provided the ndgc value will be 0\")\n",
    "        if self.binary_filename:\n",
    "            self.binary_relevance_dict = self.qrel_parser(self.binary_filename)\n",
    "            self.binary_trec_dictionary = self.trec_relevance_reader(self.trec_file)  \n",
    "            self.binary_trec_dictionary  = self.trec_relevance_conversion(self.binary_trec_dictionary, self.binary_relevance_dict) \n",
    "            for key in self.binary_trec_dictionary:\n",
    "                print (\"key\",key)\n",
    "                if not self.overall_filename:\n",
    "                     self.ndgc_all[key] = 0\n",
    "                self.df_prec_rec_f1, self.average_precision, self.r_precision_value = self.precision_overall_qrel(self.binary_trec_dictionary[key]) \n",
    "                if self.average_precision:\n",
    "                    self.result_dict[key] = [self.average_precision, self.df_prec_rec_f1, self.r_precision_value, self.ndgc_all[key]]\n",
    "        df_all_results = [i[1] for i in list(self.result_dict.values())][:]\n",
    "        self.print_result(self.query_num)\n",
    "        return df_all_results\n",
    "    \n",
    "    def trec_relevance_reader(self, trec_file):\n",
    "        with open(trec_file) as file:\n",
    "            read_file = file.readlines()\n",
    "        dictionary_query = {}\n",
    "        value = 0 #initial value\n",
    "        for i in read_file:\n",
    "            split_i = i.strip(\"\\n\").split(\" \")\n",
    "            key = split_i[0]\n",
    "            if split_i[1] == \"Q0\":\n",
    "                split_i.pop(1)\n",
    "            if key not in dictionary_query:\n",
    "                temp_dict = {}\n",
    "                temp_dict[split_i[1]] = value\n",
    "                dictionary_query[key] = temp_dict\n",
    "            else:\n",
    "                temp_dict[split_i[1]] = value\n",
    "        return dictionary_query\n",
    "    \n",
    "    def trec_relevance_conversion(self, dictionary_query, rel_dictionary):\n",
    "        new_temp_dict = {}\n",
    "        for key in dictionary_query:\n",
    "            temp_dict_each_query = dictionary_query[key]\n",
    "            if key in rel_dictionary:\n",
    "                for docid in dictionary_query[key]:\n",
    "                    if docid in rel_dictionary[key]:\n",
    "                        temp_dict_each_query[docid] = rel_dictionary[key][docid]\n",
    "            new_temp_dict[key] = temp_dict_each_query\n",
    "        return new_temp_dict\n",
    "        \n",
    "        \n",
    "    ## The formula for r precision is rank divided by total relevant docs\n",
    "    def r_precision(self, prec_dict):\n",
    "        self.r_precision_value = sum(list(prec_dict.values())[:self.total_relevance]) / self.total_relevance\n",
    "        return self.r_precision_value\n",
    "    \n",
    "    def precision_recall_f1(self):\n",
    "        list_of_indices =  range(1,201)\n",
    "        prec = []\n",
    "        recall = []\n",
    "        f1 = []\n",
    "        self.df_prec_rec_f1 = pd.DataFrame(columns = [\"prec\",\"recall\",\"f1\"], index = list_of_indices)\n",
    "        for i in list_of_indices:\n",
    "            prec.append(sum(list(self.binary_relevance_dict.values())[:i])/i)\n",
    "            recall.append(sum(list(self.binary_relevance_dict.values())[:i])/self.total_relevance)\n",
    "            sum_prec_recall = prec[i-1] + recall[i-1]\n",
    "            if sum_prec_recall == 0:\n",
    "                sum_prec_recall = 0.0001\n",
    "            f1.append((2 * prec[i-1] * recall[i-1])/sum_prec_recall)\n",
    "        self.df_prec_rec_f1[\"prec\"] = prec\n",
    "        self.df_prec_rec_f1[\"recall\"] = recall\n",
    "        self.df_prec_rec_f1[\"f1\"] = f1\n",
    "        self.average_precision = self.df_prec_rec_f1[\"prec\"].mean()\n",
    "        return self.df_prec_rec_f1, self.average_precision\n",
    "    \n",
    "    def calculate_ndcg(self, overall_relevance):\n",
    "        ## log relevance \n",
    "        print (\"Overall rele: \",len(overall_relevance.keys()))\n",
    "        log_relevance = [1/(math.log2(i+1)) for i in range(1,len(overall_relevance)+1)]\n",
    "        print (\"length of log relevance: \", len(log_relevance))\n",
    "        ## discounted gain gives more preference to the docs which are relevant and high in order\n",
    "        discounted_gain = [list(overall_relevance.values())[j]*log_relevance[j] for j in range(len(overall_relevance))]\n",
    "        print (\"discounted gain: \", sum(discounted_gain))\n",
    "        ## ideal DCG is to be used to divide the result since each query can have varied number of retrived docs\n",
    "        relative_relevance_sorted = sorted(overall_relevance.items(), key = lambda x:x[1], reverse = True)\n",
    "        ## relative_relevance_sorted is an ordered dictionary\n",
    "        normalized_gain = [relative_relevance_sorted[j][1]*log_relevance[j] for j in range(len(overall_relevance))]\n",
    "        print (\"normalized_gain: \", sum(normalized_gain))\n",
    "        ## divide the sum of discounted gain by the sum of normalized to get the ndcg\n",
    "        ndcg = sum(discounted_gain)/sum(normalized_gain)\n",
    "        print (\"ndcg\", ndcg, \"\\n\")\n",
    "        return ndcg\n",
    "    \n",
    "    def print_result(self, query_num):\n",
    "        if query_num:\n",
    "            print (\"Results for query: \",query_num)\n",
    "            average_precision = self.result_dict[query_num][0]\n",
    "            df_prec_rec_f1 = self.result_dict[query_num][1]\n",
    "            r_precision_value = self.result_dict[query_num][2]\n",
    "            ndcg = self.result_dict[query_num][3]\n",
    "            self.print_data(average_precision, df_prec_rec_f1, r_precision_value, ndcg)\n",
    "        else:\n",
    "            print (\"\\n Result on all queries\")\n",
    "            avg_precision_mean  = statistics.mean([j[0] for j in list(self.result_dict.values())])\n",
    "            avg_prec_recall_at_k  = ([j[1] for j in list(self.result_dict.values())])[:]\n",
    "            new_combined_df = avg_prec_recall_at_k[0][:]\n",
    "            for query_df in avg_prec_recall_at_k[1:]:\n",
    "                new_combined_df += query_df\n",
    "            new_combined_df = new_combined_df / len(self.result_dict)\n",
    "            avg_r_precision  = ([j[2] for j in list(self.result_dict.values())])\n",
    "            avg_r_precision = statistics.mean(avg_r_precision)\n",
    "            avg_ndgc  = ([j[3] for j in list(self.result_dict.values())])\n",
    "            avg_ndgc = statistics.mean(avg_ndgc)\n",
    "            self.print_data(avg_precision_mean, new_combined_df, avg_r_precision, avg_ndgc)\n",
    "            \n",
    "    def print_data(self,avg_precision_mean, new_combined_df, avg_r_precision, avg_ndgc):\n",
    "        print (\"Average precision: \", avg_precision_mean)\n",
    "        print (\"**********************************************************************\")\n",
    "        for i in self.indices:\n",
    "            print (\"Avg Precision at {0} : {1}\".format(i+1, new_combined_df[\"prec\"][i+1]))\n",
    "            print (\"Avg Recall at {0} : {1}\".format(i+1, new_combined_df[\"recall\"][i+1]))\n",
    "            print (\"Avg F1 at {0} : {1}\".format(i+1, new_combined_df[\"f1\"][i+1]))\n",
    "            print (\"********************************************************************\")\n",
    "        print (\"Average R precision : {}\".format(avg_r_precision))\n",
    "        print (\"Average NDCG score: \", avg_ndgc)\n",
    "\n",
    "    def qrel_parser(self, filename):\n",
    "        with open(filename) as file:\n",
    "            read_file = file.readlines()\n",
    "        dictionary_query = {}\n",
    "        for i in read_file:\n",
    "            split_i = i.strip(\"\\n\").split(\" \")\n",
    "            key = split_i[0]\n",
    "            if split_i[1] == \"0\":\n",
    "                split_i.pop(1)\n",
    "            if key not in dictionary_query:\n",
    "                temp_dict = {}\n",
    "                temp_dict[split_i[1]] = int(split_i[2])\n",
    "                dictionary_query[key] = temp_dict\n",
    "            else:\n",
    "                temp_dict[split_i[1]] = int(split_i[2])\n",
    "        return dictionary_query\n",
    "    \n",
    "    def precision_overall_qrel(self, dictionary_query):\n",
    "        precision_values = []\n",
    "        self.binary_relevance_dict = dictionary_query\n",
    "        self.total_relevance = sum(list(self.binary_relevance_dict.values()))\n",
    "        if self.total_relevance == 0:\n",
    "            return None, None, None\n",
    "        self.df_prec_rec_f1, self.average_precision = self.precision_recall_f1()\n",
    "        self.r_precision_value = self.r_precision(dictionary_query)\n",
    "        print (\"df_prec_rec_f1\",self.df_prec_rec_f1)\n",
    "        return self.df_prec_rec_f1, self.average_precision, self.r_precision_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since overall relevance file is not provided the ndgc value will be 0\n",
      "key 85\n",
      "key 59\n",
      "key 56\n",
      "key 71\n",
      "key 64\n",
      "key 62\n",
      "key 93\n",
      "key 99\n",
      "key 58\n",
      "key 77\n",
      "key 54\n",
      "key 87\n",
      "key 94\n",
      "key 100\n",
      "key 89\n",
      "key 61\n",
      "key 95\n",
      "key 68\n",
      "key 57\n",
      "key 97\n",
      "key 98\n",
      "key 60\n",
      "key 80\n",
      "key 63\n",
      "key 91\n",
      "\n",
      " Result on all queries\n",
      "new_combined_df          prec    recall        f1\n",
      "1    0.000000  0.000000  0.000000\n",
      "2    0.500000  0.005464  0.010811\n",
      "3    0.666667  0.010929  0.021505\n",
      "4    0.750000  0.016393  0.032086\n",
      "5    0.800000  0.021858  0.042553\n",
      "6    0.833333  0.027322  0.052910\n",
      "7    0.857143  0.032787  0.063158\n",
      "8    0.875000  0.038251  0.073298\n",
      "9    0.777778  0.038251  0.072917\n",
      "10   0.800000  0.043716  0.082902\n",
      "11   0.818182  0.049180  0.092784\n",
      "12   0.750000  0.049180  0.092308\n",
      "13   0.692308  0.049180  0.091837\n",
      "14   0.714286  0.054645  0.101523\n",
      "15   0.733333  0.060109  0.111111\n",
      "16   0.687500  0.060109  0.110553\n",
      "17   0.647059  0.060109  0.110000\n",
      "18   0.611111  0.060109  0.109453\n",
      "19   0.631579  0.065574  0.118812\n",
      "20   0.600000  0.065574  0.118227\n",
      "21   0.571429  0.065574  0.117647\n",
      "22   0.545455  0.065574  0.117073\n",
      "23   0.565217  0.071038  0.126214\n",
      "24   0.583333  0.076503  0.135266\n",
      "25   0.560000  0.076503  0.134615\n",
      "26   0.576923  0.081967  0.143541\n",
      "27   0.592593  0.087432  0.152381\n",
      "28   0.607143  0.092896  0.161137\n",
      "29   0.620690  0.098361  0.169811\n",
      "30   0.633333  0.103825  0.178404\n",
      "..        ...       ...       ...\n",
      "171  0.362573  0.338798  0.350282\n",
      "172  0.360465  0.338798  0.349296\n",
      "173  0.358382  0.338798  0.348315\n",
      "174  0.362069  0.344262  0.352941\n",
      "175  0.360000  0.344262  0.351955\n",
      "176  0.357955  0.344262  0.350975\n",
      "177  0.355932  0.344262  0.350000\n",
      "178  0.359551  0.349727  0.354571\n",
      "179  0.363128  0.355191  0.359116\n",
      "180  0.361111  0.355191  0.358127\n",
      "181  0.359116  0.355191  0.357143\n",
      "182  0.357143  0.355191  0.356164\n",
      "183  0.360656  0.360656  0.360656\n",
      "184  0.364130  0.366120  0.365123\n",
      "185  0.367568  0.371585  0.369565\n",
      "186  0.365591  0.371585  0.368564\n",
      "187  0.363636  0.371585  0.367568\n",
      "188  0.361702  0.371585  0.366577\n",
      "189  0.359788  0.371585  0.365591\n",
      "190  0.363158  0.377049  0.369973\n",
      "191  0.361257  0.377049  0.368984\n",
      "192  0.364583  0.382514  0.373333\n",
      "193  0.367876  0.387978  0.377660\n",
      "194  0.371134  0.393443  0.381963\n",
      "195  0.369231  0.393443  0.380952\n",
      "196  0.367347  0.393443  0.379947\n",
      "197  0.365482  0.393443  0.378947\n",
      "198  0.363636  0.393443  0.377953\n",
      "199  0.361809  0.393443  0.376963\n",
      "200  0.365000  0.398907  0.381201\n",
      "\n",
      "[200 rows x 3 columns]\n",
      "Average precision:  0.22513557000405005\n",
      "**********************************************************************\n",
      "Avg Precision at 5 : 0.36521739130434794\n",
      "Avg Recall at 5 : 0.05517497196654192\n",
      "Avg F1 at 5 : 0.08519583808191664\n",
      "********************************************************************\n",
      "Avg Precision at 10 : 0.38695652173913037\n",
      "Avg Recall at 10 : 0.13557143946349945\n",
      "Avg F1 at 10 : 0.1595111338629069\n",
      "********************************************************************\n",
      "Avg Precision at 20 : 0.3434782608695652\n",
      "Avg Recall at 20 : 0.2067117015963959\n",
      "Avg F1 at 20 : 0.20056943394622126\n",
      "********************************************************************\n",
      "Avg Precision at 50 : 0.2791304347826086\n",
      "Avg Recall at 50 : 0.36072874993926324\n",
      "Avg F1 at 50 : 0.24583545648865734\n",
      "********************************************************************\n",
      "Avg Precision at 100 : 0.20347826086956516\n",
      "Avg Recall at 100 : 0.46026504158789583\n",
      "Avg F1 at 100 : 0.23263205515255\n",
      "********************************************************************\n",
      "Avg Precision at 200 : 0.14173913043478256\n",
      "Avg Recall at 200 : 0.6481773850874675\n",
      "Avg F1 at 200 : 0.19931774347544332\n",
      "********************************************************************\n",
      "Average R precision : 0.2798428330619421\n",
      "Average NDCG score:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "judgement_result_object = JudgementClassification(file_name_overall = None,\n",
    "                                                  file_name_binary = \"qrels.adhoc.51-100.AP89.txt\", \n",
    "                                                  trec_file = \"okapi_tfidf\")\n",
    "judgement_result = judgement_result_object.call_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall rele:  200\n",
      "length of log relevance:  200\n",
      "discounted gain:  55.19248182479027\n",
      "normalized_gain:  56.700439420079796\n",
      "ndcg 0.9734048340592666 \n",
      "\n",
      "Overall rele:  200\n",
      "length of log relevance:  200\n",
      "discounted gain:  54.17333033807613\n",
      "normalized_gain:  58.11907033717446\n",
      "ndcg 0.9321093751808597 \n",
      "\n",
      "Overall rele:  200\n",
      "length of log relevance:  200\n",
      "discounted gain:  17.11430839226953\n",
      "normalized_gain:  18.13130107257709\n",
      "ndcg 0.9439095586005283 \n",
      "\n",
      "key 152601\n",
      "df_prec_rec_f1          prec  recall        f1\n",
      "1    1.000000   0.008  0.015873\n",
      "2    1.000000   0.016  0.031496\n",
      "3    1.000000   0.024  0.046875\n",
      "4    1.000000   0.032  0.062016\n",
      "5    1.000000   0.040  0.076923\n",
      "6    1.000000   0.048  0.091603\n",
      "7    1.000000   0.056  0.106061\n",
      "8    1.000000   0.064  0.120301\n",
      "9    1.000000   0.072  0.134328\n",
      "10   1.000000   0.080  0.148148\n",
      "11   1.000000   0.088  0.161765\n",
      "12   1.000000   0.096  0.175182\n",
      "13   1.000000   0.104  0.188406\n",
      "14   1.000000   0.112  0.201439\n",
      "15   1.000000   0.120  0.214286\n",
      "16   0.937500   0.120  0.212766\n",
      "17   0.941176   0.128  0.225352\n",
      "18   0.944444   0.136  0.237762\n",
      "19   0.947368   0.144  0.250000\n",
      "20   0.950000   0.152  0.262069\n",
      "21   0.904762   0.152  0.260274\n",
      "22   0.863636   0.152  0.258503\n",
      "23   0.826087   0.152  0.256757\n",
      "24   0.791667   0.152  0.255034\n",
      "25   0.800000   0.160  0.266667\n",
      "26   0.807692   0.168  0.278146\n",
      "27   0.814815   0.176  0.289474\n",
      "28   0.821429   0.184  0.300654\n",
      "29   0.793103   0.184  0.298701\n",
      "30   0.800000   0.192  0.309677\n",
      "..        ...     ...       ...\n",
      "171  0.631579   0.864  0.729730\n",
      "172  0.633721   0.872  0.734007\n",
      "173  0.630058   0.872  0.731544\n",
      "174  0.626437   0.872  0.729097\n",
      "175  0.628571   0.880  0.733333\n",
      "176  0.630682   0.888  0.737542\n",
      "177  0.627119   0.888  0.735099\n",
      "178  0.623596   0.888  0.732673\n",
      "179  0.625698   0.896  0.736842\n",
      "180  0.622222   0.896  0.734426\n",
      "181  0.624309   0.904  0.738562\n",
      "182  0.620879   0.904  0.736156\n",
      "183  0.622951   0.912  0.740260\n",
      "184  0.625000   0.920  0.744337\n",
      "185  0.627027   0.928  0.748387\n",
      "186  0.623656   0.928  0.745981\n",
      "187  0.625668   0.936  0.750000\n",
      "188  0.627660   0.944  0.753994\n",
      "189  0.629630   0.952  0.757962\n",
      "190  0.626316   0.952  0.755556\n",
      "191  0.623037   0.952  0.753165\n",
      "192  0.625000   0.960  0.757098\n",
      "193  0.626943   0.968  0.761006\n",
      "194  0.628866   0.976  0.764890\n",
      "195  0.630769   0.984  0.768750\n",
      "196  0.632653   0.992  0.772586\n",
      "197  0.629442   0.992  0.770186\n",
      "198  0.626263   0.992  0.767802\n",
      "199  0.623116   0.992  0.765432\n",
      "200  0.625000   1.000  0.769231\n",
      "\n",
      "[200 rows x 3 columns]\n",
      "key 152602\n",
      "df_prec_rec_f1          prec    recall        f1\n",
      "1    0.000000  0.000000  0.000000\n",
      "2    0.500000  0.008621  0.016949\n",
      "3    0.666667  0.017241  0.033613\n",
      "4    0.500000  0.017241  0.033333\n",
      "5    0.400000  0.017241  0.033058\n",
      "6    0.333333  0.017241  0.032787\n",
      "7    0.428571  0.025862  0.048780\n",
      "8    0.375000  0.025862  0.048387\n",
      "9    0.333333  0.025862  0.048000\n",
      "10   0.300000  0.025862  0.047619\n",
      "11   0.272727  0.025862  0.047244\n",
      "12   0.250000  0.025862  0.046875\n",
      "13   0.230769  0.025862  0.046512\n",
      "14   0.214286  0.025862  0.046154\n",
      "15   0.200000  0.025862  0.045802\n",
      "16   0.187500  0.025862  0.045455\n",
      "17   0.176471  0.025862  0.045113\n",
      "18   0.222222  0.034483  0.059701\n",
      "19   0.263158  0.043103  0.074074\n",
      "20   0.250000  0.043103  0.073529\n",
      "21   0.285714  0.051724  0.087591\n",
      "22   0.272727  0.051724  0.086957\n",
      "23   0.304348  0.060345  0.100719\n",
      "24   0.291667  0.060345  0.100000\n",
      "25   0.280000  0.060345  0.099291\n",
      "26   0.269231  0.060345  0.098592\n",
      "27   0.259259  0.060345  0.097902\n",
      "28   0.285714  0.068966  0.111111\n",
      "29   0.310345  0.077586  0.124138\n",
      "30   0.333333  0.086207  0.136986\n",
      "..        ...       ...       ...\n",
      "171  0.614035  0.905172  0.731707\n",
      "172  0.610465  0.905172  0.729167\n",
      "173  0.612717  0.913793  0.733564\n",
      "174  0.609195  0.913793  0.731034\n",
      "175  0.611429  0.922414  0.735395\n",
      "176  0.613636  0.931034  0.739726\n",
      "177  0.615819  0.939655  0.744027\n",
      "178  0.612360  0.939655  0.741497\n",
      "179  0.608939  0.939655  0.738983\n",
      "180  0.605556  0.939655  0.736486\n",
      "181  0.602210  0.939655  0.734007\n",
      "182  0.598901  0.939655  0.731544\n",
      "183  0.601093  0.948276  0.735786\n",
      "184  0.603261  0.956897  0.740000\n",
      "185  0.600000  0.956897  0.737542\n",
      "186  0.596774  0.956897  0.735099\n",
      "187  0.593583  0.956897  0.732673\n",
      "188  0.590426  0.956897  0.730263\n",
      "189  0.592593  0.965517  0.734426\n",
      "190  0.589474  0.965517  0.732026\n",
      "191  0.586387  0.965517  0.729642\n",
      "192  0.588542  0.974138  0.733766\n",
      "193  0.590674  0.982759  0.737864\n",
      "194  0.587629  0.982759  0.735484\n",
      "195  0.589744  0.991379  0.739550\n",
      "196  0.586735  0.991379  0.737179\n",
      "197  0.588832  1.000000  0.741214\n",
      "198  0.585859  1.000000  0.738854\n",
      "199  0.582915  1.000000  0.736508\n",
      "200  0.580000  1.000000  0.734177\n",
      "\n",
      "[200 rows x 3 columns]\n",
      "key 152603\n",
      "df_prec_rec_f1          prec    recall        f1\n",
      "1    1.000000  0.030303  0.058824\n",
      "2    1.000000  0.060606  0.114286\n",
      "3    1.000000  0.090909  0.166667\n",
      "4    1.000000  0.121212  0.216216\n",
      "5    0.800000  0.121212  0.210526\n",
      "6    0.833333  0.151515  0.256410\n",
      "7    0.857143  0.181818  0.300000\n",
      "8    0.750000  0.181818  0.292683\n",
      "9    0.777778  0.212121  0.333333\n",
      "10   0.700000  0.212121  0.325581\n",
      "11   0.727273  0.242424  0.363636\n",
      "12   0.750000  0.272727  0.400000\n",
      "13   0.769231  0.303030  0.434783\n",
      "14   0.785714  0.333333  0.468085\n",
      "15   0.733333  0.333333  0.458333\n",
      "16   0.750000  0.363636  0.489796\n",
      "17   0.764706  0.393939  0.520000\n",
      "18   0.777778  0.424242  0.549020\n",
      "19   0.789474  0.454545  0.576923\n",
      "20   0.800000  0.484848  0.603774\n",
      "21   0.761905  0.484848  0.592593\n",
      "22   0.727273  0.484848  0.581818\n",
      "23   0.695652  0.484848  0.571429\n",
      "24   0.708333  0.515152  0.596491\n",
      "25   0.680000  0.515152  0.586207\n",
      "26   0.653846  0.515152  0.576271\n",
      "27   0.629630  0.515152  0.566667\n",
      "28   0.642857  0.545455  0.590164\n",
      "29   0.655172  0.575758  0.612903\n",
      "30   0.666667  0.606061  0.634921\n",
      "..        ...       ...       ...\n",
      "171  0.152047  0.787879  0.254902\n",
      "172  0.151163  0.787879  0.253659\n",
      "173  0.150289  0.787879  0.252427\n",
      "174  0.149425  0.787879  0.251208\n",
      "175  0.148571  0.787879  0.250000\n",
      "176  0.147727  0.787879  0.248804\n",
      "177  0.146893  0.787879  0.247619\n",
      "178  0.146067  0.787879  0.246445\n",
      "179  0.145251  0.787879  0.245283\n",
      "180  0.144444  0.787879  0.244131\n",
      "181  0.143646  0.787879  0.242991\n",
      "182  0.142857  0.787879  0.241860\n",
      "183  0.142077  0.787879  0.240741\n",
      "184  0.141304  0.787879  0.239631\n",
      "185  0.140541  0.787879  0.238532\n",
      "186  0.139785  0.787879  0.237443\n",
      "187  0.139037  0.787879  0.236364\n",
      "188  0.138298  0.787879  0.235294\n",
      "189  0.137566  0.787879  0.234234\n",
      "190  0.136842  0.787879  0.233184\n",
      "191  0.136126  0.787879  0.232143\n",
      "192  0.135417  0.787879  0.231111\n",
      "193  0.134715  0.787879  0.230088\n",
      "194  0.139175  0.818182  0.237885\n",
      "195  0.143590  0.848485  0.245614\n",
      "196  0.147959  0.878788  0.253275\n",
      "197  0.152284  0.909091  0.260870\n",
      "198  0.156566  0.939394  0.268398\n",
      "199  0.160804  0.969697  0.275862\n",
      "200  0.165000  1.000000  0.283262\n",
      "\n",
      "[200 rows x 3 columns]\n",
      "Results for query:  152601\n",
      "Average precision:  0.7338722395176808\n",
      "**********************************************************************\n",
      "Avg Precision at 5 : 1.0\n",
      "Avg Recall at 5 : 0.04\n",
      "Avg F1 at 5 : 0.07692307692307693\n",
      "********************************************************************\n",
      "Avg Precision at 10 : 1.0\n",
      "Avg Recall at 10 : 0.08\n",
      "Avg F1 at 10 : 0.14814814814814814\n",
      "********************************************************************\n",
      "Avg Precision at 20 : 0.95\n",
      "Avg Recall at 20 : 0.152\n",
      "Avg F1 at 20 : 0.2620689655172414\n",
      "********************************************************************\n",
      "Avg Precision at 50 : 0.76\n",
      "Avg Recall at 50 : 0.304\n",
      "Avg F1 at 50 : 0.4342857142857143\n",
      "********************************************************************\n",
      "Avg Precision at 100 : 0.69\n",
      "Avg Recall at 100 : 0.552\n",
      "Avg F1 at 100 : 0.6133333333333333\n",
      "********************************************************************\n",
      "Avg Precision at 200 : 0.625\n",
      "Avg Recall at 200 : 1.0\n",
      "Avg F1 at 200 : 0.7692307692307693\n",
      "********************************************************************\n",
      "Average R precision : 0.704\n",
      "Average NDCG score:  0.9734048340592666\n"
     ]
    }
   ],
   "source": [
    "judgement_result_object = JudgementClassification(file_name_overall = \"crawler_query_overall.txt\",\n",
    "                                                  file_name_binary = \"crawler_query_binary.txt\", \n",
    "                                                  trec_file = \"crawler_query_overall.txt\", query_num = \"152601\")\n",
    "judgement_result = judgement_result_object.call_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cef1d9b128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(judgement_result[0][\"prec\"],judgement_result[0][\"recall\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cef1bc9390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(judgement_result[1][\"prec\"],judgement_result[1][\"recall\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSAip3EVEQkjlLiISQip3EZEQ+v+H1jx4AUlsFwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1cef2055e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(judgement_result[2][\"prec\"],judgement_result[2][\"recall\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.033613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.033058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.032787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.048387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.048000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.047619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.047244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.046154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.045802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.025862</td>\n",
       "      <td>0.045113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.059701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.074074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.073529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.087591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.060345</td>\n",
       "      <td>0.100719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.060345</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.060345</td>\n",
       "      <td>0.099291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.060345</td>\n",
       "      <td>0.098592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.060345</td>\n",
       "      <td>0.097902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.124138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.136986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.731707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.610465</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.612717</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.733564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.731034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.611429</td>\n",
       "      <td>0.922414</td>\n",
       "      <td>0.735395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.739726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.615819</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.744027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.612360</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.741497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.608939</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.738983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.605556</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.736486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.602210</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.734007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.598901</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.731544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.601093</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.735786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.603261</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.737542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.735099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.593583</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.732673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.590426</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.730263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.734426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.589474</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.732026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.586387</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.729642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.588542</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.733766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.590674</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.737864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.735484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.739550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.586735</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.737179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.588832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.741214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.585859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.582915</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.736508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.734177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prec    recall        f1\n",
       "1    0.000000  0.000000  0.000000\n",
       "2    0.500000  0.008621  0.016949\n",
       "3    0.666667  0.017241  0.033613\n",
       "4    0.500000  0.017241  0.033333\n",
       "5    0.400000  0.017241  0.033058\n",
       "6    0.333333  0.017241  0.032787\n",
       "7    0.428571  0.025862  0.048780\n",
       "8    0.375000  0.025862  0.048387\n",
       "9    0.333333  0.025862  0.048000\n",
       "10   0.300000  0.025862  0.047619\n",
       "11   0.272727  0.025862  0.047244\n",
       "12   0.250000  0.025862  0.046875\n",
       "13   0.230769  0.025862  0.046512\n",
       "14   0.214286  0.025862  0.046154\n",
       "15   0.200000  0.025862  0.045802\n",
       "16   0.187500  0.025862  0.045455\n",
       "17   0.176471  0.025862  0.045113\n",
       "18   0.222222  0.034483  0.059701\n",
       "19   0.263158  0.043103  0.074074\n",
       "20   0.250000  0.043103  0.073529\n",
       "21   0.285714  0.051724  0.087591\n",
       "22   0.272727  0.051724  0.086957\n",
       "23   0.304348  0.060345  0.100719\n",
       "24   0.291667  0.060345  0.100000\n",
       "25   0.280000  0.060345  0.099291\n",
       "26   0.269231  0.060345  0.098592\n",
       "27   0.259259  0.060345  0.097902\n",
       "28   0.285714  0.068966  0.111111\n",
       "29   0.310345  0.077586  0.124138\n",
       "30   0.333333  0.086207  0.136986\n",
       "..        ...       ...       ...\n",
       "171  0.614035  0.905172  0.731707\n",
       "172  0.610465  0.905172  0.729167\n",
       "173  0.612717  0.913793  0.733564\n",
       "174  0.609195  0.913793  0.731034\n",
       "175  0.611429  0.922414  0.735395\n",
       "176  0.613636  0.931034  0.739726\n",
       "177  0.615819  0.939655  0.744027\n",
       "178  0.612360  0.939655  0.741497\n",
       "179  0.608939  0.939655  0.738983\n",
       "180  0.605556  0.939655  0.736486\n",
       "181  0.602210  0.939655  0.734007\n",
       "182  0.598901  0.939655  0.731544\n",
       "183  0.601093  0.948276  0.735786\n",
       "184  0.603261  0.956897  0.740000\n",
       "185  0.600000  0.956897  0.737542\n",
       "186  0.596774  0.956897  0.735099\n",
       "187  0.593583  0.956897  0.732673\n",
       "188  0.590426  0.956897  0.730263\n",
       "189  0.592593  0.965517  0.734426\n",
       "190  0.589474  0.965517  0.732026\n",
       "191  0.586387  0.965517  0.729642\n",
       "192  0.588542  0.974138  0.733766\n",
       "193  0.590674  0.982759  0.737864\n",
       "194  0.587629  0.982759  0.735484\n",
       "195  0.589744  0.991379  0.739550\n",
       "196  0.586735  0.991379  0.737179\n",
       "197  0.588832  1.000000  0.741214\n",
       "198  0.585859  1.000000  0.738854\n",
       "199  0.582915  1.000000  0.736508\n",
       "200  0.580000  1.000000  0.734177\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0519481</td>\n",
       "      <td>0.0998597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.11177</td>\n",
       "      <td>0.207812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.66667</td>\n",
       "      <td>0.171592</td>\n",
       "      <td>0.308986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.22354</td>\n",
       "      <td>0.38886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.2</td>\n",
       "      <td>0.230034</td>\n",
       "      <td>0.389492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.16667</td>\n",
       "      <td>0.281982</td>\n",
       "      <td>0.462218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.28571</td>\n",
       "      <td>0.341804</td>\n",
       "      <td>0.545526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.25</td>\n",
       "      <td>0.393752</td>\n",
       "      <td>0.609877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.22222</td>\n",
       "      <td>0.4457</td>\n",
       "      <td>0.670676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.1</td>\n",
       "      <td>0.452193</td>\n",
       "      <td>0.665747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.09091</td>\n",
       "      <td>0.504142</td>\n",
       "      <td>0.722266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.08333</td>\n",
       "      <td>0.55609</td>\n",
       "      <td>0.775979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.07692</td>\n",
       "      <td>0.608038</td>\n",
       "      <td>0.827117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.07143</td>\n",
       "      <td>0.659986</td>\n",
       "      <td>0.875887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0.666479</td>\n",
       "      <td>0.868417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0.718427</td>\n",
       "      <td>0.914404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.94118</td>\n",
       "      <td>0.724921</td>\n",
       "      <td>0.907164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0.784743</td>\n",
       "      <td>0.964475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>0.79911</td>\n",
       "      <td>0.971073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.95</td>\n",
       "      <td>0.805604</td>\n",
       "      <td>0.964579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.95238</td>\n",
       "      <td>0.819971</td>\n",
       "      <td>0.972244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.90909</td>\n",
       "      <td>0.826465</td>\n",
       "      <td>0.966901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.86957</td>\n",
       "      <td>0.834339</td>\n",
       "      <td>0.964143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.875</td>\n",
       "      <td>0.887667</td>\n",
       "      <td>1.00533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.84</td>\n",
       "      <td>0.894161</td>\n",
       "      <td>1.00054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.80769</td>\n",
       "      <td>0.900654</td>\n",
       "      <td>0.996242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.77778</td>\n",
       "      <td>0.907148</td>\n",
       "      <td>0.992384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.82143</td>\n",
       "      <td>0.96697</td>\n",
       "      <td>1.04184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.82759</td>\n",
       "      <td>1.0203</td>\n",
       "      <td>1.07902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.83333</td>\n",
       "      <td>1.03467</td>\n",
       "      <td>1.08745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.5614</td>\n",
       "      <td>2.71071</td>\n",
       "      <td>1.79558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.55814</td>\n",
       "      <td>2.7172</td>\n",
       "      <td>1.79554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.55491</td>\n",
       "      <td>2.72507</td>\n",
       "      <td>1.79606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.55172</td>\n",
       "      <td>2.73157</td>\n",
       "      <td>1.79603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.55429</td>\n",
       "      <td>2.74594</td>\n",
       "      <td>1.80262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.55682</td>\n",
       "      <td>2.7603</td>\n",
       "      <td>1.80918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.55932</td>\n",
       "      <td>2.77467</td>\n",
       "      <td>1.8157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.55056</td>\n",
       "      <td>2.77467</td>\n",
       "      <td>1.8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.54749</td>\n",
       "      <td>2.78116</td>\n",
       "      <td>1.80956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.54444</td>\n",
       "      <td>2.78766</td>\n",
       "      <td>1.80951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.54144</td>\n",
       "      <td>2.79415</td>\n",
       "      <td>1.80947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.53297</td>\n",
       "      <td>2.79415</td>\n",
       "      <td>1.80349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.53552</td>\n",
       "      <td>2.80852</td>\n",
       "      <td>1.80993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.53804</td>\n",
       "      <td>2.82289</td>\n",
       "      <td>1.81634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.54054</td>\n",
       "      <td>2.83725</td>\n",
       "      <td>1.82271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.53226</td>\n",
       "      <td>2.83725</td>\n",
       "      <td>1.81677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.52941</td>\n",
       "      <td>2.84375</td>\n",
       "      <td>1.81674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.5266</td>\n",
       "      <td>2.85024</td>\n",
       "      <td>1.81671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.5291</td>\n",
       "      <td>2.86461</td>\n",
       "      <td>1.82301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.52105</td>\n",
       "      <td>2.86461</td>\n",
       "      <td>1.81716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.51309</td>\n",
       "      <td>2.86461</td>\n",
       "      <td>1.81135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.51562</td>\n",
       "      <td>2.87898</td>\n",
       "      <td>1.81762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.51813</td>\n",
       "      <td>2.89334</td>\n",
       "      <td>1.82386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.52062</td>\n",
       "      <td>2.94529</td>\n",
       "      <td>1.83309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.52308</td>\n",
       "      <td>2.95966</td>\n",
       "      <td>1.83924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.52041</td>\n",
       "      <td>2.96615</td>\n",
       "      <td>1.83916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.52284</td>\n",
       "      <td>2.98052</td>\n",
       "      <td>1.84526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.5202</td>\n",
       "      <td>2.98701</td>\n",
       "      <td>1.84517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.51759</td>\n",
       "      <td>2.99351</td>\n",
       "      <td>1.84509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.515</td>\n",
       "      <td>3</td>\n",
       "      <td>1.84501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        prec     recall         f1\n",
       "1          2  0.0519481  0.0998597\n",
       "2        2.5    0.11177   0.207812\n",
       "3    2.66667   0.171592   0.308986\n",
       "4        2.5    0.22354    0.38886\n",
       "5        2.2   0.230034   0.389492\n",
       "6    2.16667   0.281982   0.462218\n",
       "7    2.28571   0.341804   0.545526\n",
       "8       2.25   0.393752   0.609877\n",
       "9    2.22222     0.4457   0.670676\n",
       "10       2.1   0.452193   0.665747\n",
       "11   2.09091   0.504142   0.722266\n",
       "12   2.08333    0.55609   0.775979\n",
       "13   2.07692   0.608038   0.827117\n",
       "14   2.07143   0.659986   0.875887\n",
       "15         2   0.666479   0.868417\n",
       "16         2   0.718427   0.914404\n",
       "17   1.94118   0.724921   0.907164\n",
       "18         2   0.784743   0.964475\n",
       "19         2    0.79911   0.971073\n",
       "20      1.95   0.805604   0.964579\n",
       "21   1.95238   0.819971   0.972244\n",
       "22   1.90909   0.826465   0.966901\n",
       "23   1.86957   0.834339   0.964143\n",
       "24     1.875   0.887667    1.00533\n",
       "25      1.84   0.894161    1.00054\n",
       "26   1.80769   0.900654   0.996242\n",
       "27   1.77778   0.907148   0.992384\n",
       "28   1.82143    0.96697    1.04184\n",
       "29   1.82759     1.0203    1.07902\n",
       "30   1.83333    1.03467    1.08745\n",
       "..       ...        ...        ...\n",
       "171   1.5614    2.71071    1.79558\n",
       "172  1.55814     2.7172    1.79554\n",
       "173  1.55491    2.72507    1.79606\n",
       "174  1.55172    2.73157    1.79603\n",
       "175  1.55429    2.74594    1.80262\n",
       "176  1.55682     2.7603    1.80918\n",
       "177  1.55932    2.77467     1.8157\n",
       "178  1.55056    2.77467     1.8096\n",
       "179  1.54749    2.78116    1.80956\n",
       "180  1.54444    2.78766    1.80951\n",
       "181  1.54144    2.79415    1.80947\n",
       "182  1.53297    2.79415    1.80349\n",
       "183  1.53552    2.80852    1.80993\n",
       "184  1.53804    2.82289    1.81634\n",
       "185  1.54054    2.83725    1.82271\n",
       "186  1.53226    2.83725    1.81677\n",
       "187  1.52941    2.84375    1.81674\n",
       "188   1.5266    2.85024    1.81671\n",
       "189   1.5291    2.86461    1.82301\n",
       "190  1.52105    2.86461    1.81716\n",
       "191  1.51309    2.86461    1.81135\n",
       "192  1.51562    2.87898    1.81762\n",
       "193  1.51813    2.89334    1.82386\n",
       "194  1.52062    2.94529    1.83309\n",
       "195  1.52308    2.95966    1.83924\n",
       "196  1.52041    2.96615    1.83916\n",
       "197  1.52284    2.98052    1.84526\n",
       "198   1.5202    2.98701    1.84517\n",
       "199  1.51759    2.99351    1.84509\n",
       "200    1.515          3    1.84501\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prec</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0519481</td>\n",
       "      <td>0.0998597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.11177</td>\n",
       "      <td>0.207812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.66667</td>\n",
       "      <td>0.171592</td>\n",
       "      <td>0.308986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.22354</td>\n",
       "      <td>0.38886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.2</td>\n",
       "      <td>0.230034</td>\n",
       "      <td>0.389492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.16667</td>\n",
       "      <td>0.281982</td>\n",
       "      <td>0.462218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.28571</td>\n",
       "      <td>0.341804</td>\n",
       "      <td>0.545526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.25</td>\n",
       "      <td>0.393752</td>\n",
       "      <td>0.609877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.22222</td>\n",
       "      <td>0.4457</td>\n",
       "      <td>0.670676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.1</td>\n",
       "      <td>0.452193</td>\n",
       "      <td>0.665747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.09091</td>\n",
       "      <td>0.504142</td>\n",
       "      <td>0.722266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.08333</td>\n",
       "      <td>0.55609</td>\n",
       "      <td>0.775979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.07692</td>\n",
       "      <td>0.608038</td>\n",
       "      <td>0.827117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.07143</td>\n",
       "      <td>0.659986</td>\n",
       "      <td>0.875887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0.666479</td>\n",
       "      <td>0.868417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>0.718427</td>\n",
       "      <td>0.914404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.94118</td>\n",
       "      <td>0.724921</td>\n",
       "      <td>0.907164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>0.784743</td>\n",
       "      <td>0.964475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>0.79911</td>\n",
       "      <td>0.971073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.95</td>\n",
       "      <td>0.805604</td>\n",
       "      <td>0.964579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.95238</td>\n",
       "      <td>0.819971</td>\n",
       "      <td>0.972244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.90909</td>\n",
       "      <td>0.826465</td>\n",
       "      <td>0.966901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.86957</td>\n",
       "      <td>0.834339</td>\n",
       "      <td>0.964143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.875</td>\n",
       "      <td>0.887667</td>\n",
       "      <td>1.00533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.84</td>\n",
       "      <td>0.894161</td>\n",
       "      <td>1.00054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.80769</td>\n",
       "      <td>0.900654</td>\n",
       "      <td>0.996242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.77778</td>\n",
       "      <td>0.907148</td>\n",
       "      <td>0.992384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.82143</td>\n",
       "      <td>0.96697</td>\n",
       "      <td>1.04184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.82759</td>\n",
       "      <td>1.0203</td>\n",
       "      <td>1.07902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.83333</td>\n",
       "      <td>1.03467</td>\n",
       "      <td>1.08745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>1.5614</td>\n",
       "      <td>2.71071</td>\n",
       "      <td>1.79558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.55814</td>\n",
       "      <td>2.7172</td>\n",
       "      <td>1.79554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.55491</td>\n",
       "      <td>2.72507</td>\n",
       "      <td>1.79606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1.55172</td>\n",
       "      <td>2.73157</td>\n",
       "      <td>1.79603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.55429</td>\n",
       "      <td>2.74594</td>\n",
       "      <td>1.80262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1.55682</td>\n",
       "      <td>2.7603</td>\n",
       "      <td>1.80918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1.55932</td>\n",
       "      <td>2.77467</td>\n",
       "      <td>1.8157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.55056</td>\n",
       "      <td>2.77467</td>\n",
       "      <td>1.8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.54749</td>\n",
       "      <td>2.78116</td>\n",
       "      <td>1.80956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>1.54444</td>\n",
       "      <td>2.78766</td>\n",
       "      <td>1.80951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.54144</td>\n",
       "      <td>2.79415</td>\n",
       "      <td>1.80947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.53297</td>\n",
       "      <td>2.79415</td>\n",
       "      <td>1.80349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>1.53552</td>\n",
       "      <td>2.80852</td>\n",
       "      <td>1.80993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.53804</td>\n",
       "      <td>2.82289</td>\n",
       "      <td>1.81634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.54054</td>\n",
       "      <td>2.83725</td>\n",
       "      <td>1.82271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1.53226</td>\n",
       "      <td>2.83725</td>\n",
       "      <td>1.81677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1.52941</td>\n",
       "      <td>2.84375</td>\n",
       "      <td>1.81674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.5266</td>\n",
       "      <td>2.85024</td>\n",
       "      <td>1.81671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1.5291</td>\n",
       "      <td>2.86461</td>\n",
       "      <td>1.82301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1.52105</td>\n",
       "      <td>2.86461</td>\n",
       "      <td>1.81716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1.51309</td>\n",
       "      <td>2.86461</td>\n",
       "      <td>1.81135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>1.51562</td>\n",
       "      <td>2.87898</td>\n",
       "      <td>1.81762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1.51813</td>\n",
       "      <td>2.89334</td>\n",
       "      <td>1.82386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1.52062</td>\n",
       "      <td>2.94529</td>\n",
       "      <td>1.83309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.52308</td>\n",
       "      <td>2.95966</td>\n",
       "      <td>1.83924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.52041</td>\n",
       "      <td>2.96615</td>\n",
       "      <td>1.83916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>1.52284</td>\n",
       "      <td>2.98052</td>\n",
       "      <td>1.84526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.5202</td>\n",
       "      <td>2.98701</td>\n",
       "      <td>1.84517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>1.51759</td>\n",
       "      <td>2.99351</td>\n",
       "      <td>1.84509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>1.515</td>\n",
       "      <td>3</td>\n",
       "      <td>1.84501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        prec     recall         f1\n",
       "1          2  0.0519481  0.0998597\n",
       "2        2.5    0.11177   0.207812\n",
       "3    2.66667   0.171592   0.308986\n",
       "4        2.5    0.22354    0.38886\n",
       "5        2.2   0.230034   0.389492\n",
       "6    2.16667   0.281982   0.462218\n",
       "7    2.28571   0.341804   0.545526\n",
       "8       2.25   0.393752   0.609877\n",
       "9    2.22222     0.4457   0.670676\n",
       "10       2.1   0.452193   0.665747\n",
       "11   2.09091   0.504142   0.722266\n",
       "12   2.08333    0.55609   0.775979\n",
       "13   2.07692   0.608038   0.827117\n",
       "14   2.07143   0.659986   0.875887\n",
       "15         2   0.666479   0.868417\n",
       "16         2   0.718427   0.914404\n",
       "17   1.94118   0.724921   0.907164\n",
       "18         2   0.784743   0.964475\n",
       "19         2    0.79911   0.971073\n",
       "20      1.95   0.805604   0.964579\n",
       "21   1.95238   0.819971   0.972244\n",
       "22   1.90909   0.826465   0.966901\n",
       "23   1.86957   0.834339   0.964143\n",
       "24     1.875   0.887667    1.00533\n",
       "25      1.84   0.894161    1.00054\n",
       "26   1.80769   0.900654   0.996242\n",
       "27   1.77778   0.907148   0.992384\n",
       "28   1.82143    0.96697    1.04184\n",
       "29   1.82759     1.0203    1.07902\n",
       "30   1.83333    1.03467    1.08745\n",
       "..       ...        ...        ...\n",
       "171   1.5614    2.71071    1.79558\n",
       "172  1.55814     2.7172    1.79554\n",
       "173  1.55491    2.72507    1.79606\n",
       "174  1.55172    2.73157    1.79603\n",
       "175  1.55429    2.74594    1.80262\n",
       "176  1.55682     2.7603    1.80918\n",
       "177  1.55932    2.77467     1.8157\n",
       "178  1.55056    2.77467     1.8096\n",
       "179  1.54749    2.78116    1.80956\n",
       "180  1.54444    2.78766    1.80951\n",
       "181  1.54144    2.79415    1.80947\n",
       "182  1.53297    2.79415    1.80349\n",
       "183  1.53552    2.80852    1.80993\n",
       "184  1.53804    2.82289    1.81634\n",
       "185  1.54054    2.83725    1.82271\n",
       "186  1.53226    2.83725    1.81677\n",
       "187  1.52941    2.84375    1.81674\n",
       "188   1.5266    2.85024    1.81671\n",
       "189   1.5291    2.86461    1.82301\n",
       "190  1.52105    2.86461    1.81716\n",
       "191  1.51309    2.86461    1.81135\n",
       "192  1.51562    2.87898    1.81762\n",
       "193  1.51813    2.89334    1.82386\n",
       "194  1.52062    2.94529    1.83309\n",
       "195  1.52308    2.95966    1.83924\n",
       "196  1.52041    2.96615    1.83916\n",
       "197  1.52284    2.98052    1.84526\n",
       "198   1.5202    2.98701    1.84517\n",
       "199  1.51759    2.99351    1.84509\n",
       "200    1.515          3    1.84501\n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30939293073419183,          prec     recall         f1\n",
       " 1           1  0.0454545  0.0869565\n",
       " 2           1  0.0909091   0.166667\n",
       " 3           1   0.136364       0.24\n",
       " 4           1   0.181818   0.307692\n",
       " 5         0.8   0.181818   0.296296\n",
       " 6    0.833333   0.227273   0.357143\n",
       " 7    0.857143   0.272727   0.413793\n",
       " 8       0.875   0.318182   0.466667\n",
       " 9    0.888889   0.363636   0.516129\n",
       " 10        0.8   0.363636        0.5\n",
       " 11   0.818182   0.409091   0.545455\n",
       " 12   0.833333   0.454545   0.588235\n",
       " 13   0.846154        0.5   0.628571\n",
       " 14   0.857143   0.545455   0.666667\n",
       " 15        0.8   0.545455   0.648649\n",
       " 16     0.8125   0.590909   0.684211\n",
       " 17   0.764706   0.590909   0.666667\n",
       " 18   0.777778   0.636364        0.7\n",
       " 19   0.736842   0.636364   0.682927\n",
       " 20        0.7   0.636364   0.666667\n",
       " 21   0.666667   0.636364   0.651163\n",
       " 22   0.636364   0.636364   0.636364\n",
       " 23   0.608696   0.636364   0.622222\n",
       " 24      0.625   0.681818   0.652174\n",
       " 25        0.6   0.681818   0.638298\n",
       " 26   0.576923   0.681818      0.625\n",
       " 27   0.555556   0.681818   0.612245\n",
       " 28   0.571429   0.727273       0.64\n",
       " 29   0.586207   0.772727   0.666667\n",
       " 30   0.566667   0.772727   0.653846\n",
       " ..        ...        ...        ...\n",
       " 171  0.122807   0.954545   0.217617\n",
       " 172  0.122093   0.954545   0.216495\n",
       " 173  0.121387   0.954545   0.215385\n",
       " 174   0.12069   0.954545   0.214286\n",
       " 175      0.12   0.954545   0.213198\n",
       " 176  0.119318   0.954545   0.212121\n",
       " 177  0.118644   0.954545   0.211055\n",
       " 178  0.117978   0.954545       0.21\n",
       " 179  0.117318   0.954545   0.208955\n",
       " 180  0.116667   0.954545   0.207921\n",
       " 181  0.116022   0.954545   0.206897\n",
       " 182  0.115385   0.954545   0.205882\n",
       " 183  0.114754   0.954545   0.204878\n",
       " 184   0.11413   0.954545   0.203883\n",
       " 185  0.113514   0.954545   0.202899\n",
       " 186  0.112903   0.954545   0.201923\n",
       " 187  0.112299   0.954545   0.200957\n",
       " 188  0.111702   0.954545        0.2\n",
       " 189  0.111111   0.954545   0.199052\n",
       " 190  0.110526   0.954545   0.198113\n",
       " 191  0.109948   0.954545   0.197183\n",
       " 192  0.109375   0.954545   0.196262\n",
       " 193  0.108808   0.954545   0.195349\n",
       " 194  0.113402          1   0.203704\n",
       " 195  0.112821          1   0.202765\n",
       " 196  0.112245          1   0.201835\n",
       " 197  0.111675          1   0.200913\n",
       " 198  0.111111          1        0.2\n",
       " 199  0.110553          1   0.199095\n",
       " 200      0.11          1   0.198198\n",
       " \n",
       " [200 rows x 3 columns], {5: 0.22727272727272727,\n",
       "  10: 0.45454545454545453,\n",
       "  20: 0.9090909090909091,\n",
       "  50: 2.272727272727273,\n",
       "  100: 4.545454545454546}, 0.9481247049019408]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result_dict.values())[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-precision, Average Precision, nDCG, precision@k and recall@k and F1@k (k=5,10, 20, 50, 100). \n",
    "Average these numbers over the queryIDs. If run with -q option your program should display the \n",
    "measures for each queryID before displaying the averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
